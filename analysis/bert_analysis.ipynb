{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "obvious-reception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from collections import Counter\n",
    "import http.client, urllib.parse, json, time, sys\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "sys.path.append(\"../words\")\n",
    "import we\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import numpy as np\n",
    "import re, sys\n",
    "import random\n",
    "import scipy\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import statsmodels.stats.proportion\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "import sklearn.feature_selection \n",
    "from nltk.stem.porter import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import os, json\n",
    "import re\n",
    "import textblob\n",
    "import langdetect\n",
    "import pickle as pkl\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import we\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "# from mag.experiment import Experiment\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "# In [2]:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pkl.load(open('results/joint_predictions_bert.pkl','rb'))\n",
    "predictions = scipy.special.softmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "photographic-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_preds = pkl.load(open('results/balsample__predictions_bert.pkl','rb'))\n",
    "pr_preds= scipy.special.softmax(pr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "stock-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_predictions = pkl.load(open('results/gender_predictions_bal_test.pkl','rb'))\n",
    "gender_predictions = scipy.special.softmax(gender_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "therapeutic-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73     43044\n",
      "           1       0.68      0.67      0.68     36538\n",
      "\n",
      "    accuracy                           0.71     79582\n",
      "   macro avg       0.70      0.70      0.70     79582\n",
      "weighted avg       0.71      0.71      0.71     79582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load bios data\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "df_test = pd.read_csv('csvs/multilabel_bios_test.csv')\n",
    "\n",
    "preds = gender_predictions\n",
    "preds = np.argmax(preds, axis=1).flatten()\n",
    "print(classification_report(np.array(df_test['gender']),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word-embedding based classifier\n",
    "balanced_gender_clf = pkl.load(open('results/we_bal_g.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "standard-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bios data\n",
    "from sklearn.metrics import classification_report\n",
    "df_test = pd.read_csv('csvs/multilabel_bios_test.csv')\n",
    "occs_full = np.unique(df_test['title'])\n",
    "ind_dict = dict(zip(occs_full, range(len(occs_full))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "classical-cleveland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440099519991958\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of BERT classifier with pre-processing\n",
    "preds = pr_preds\n",
    "preds = np.argmax(preds, axis=1).flatten()\n",
    "print(sklearn.metrics.accuracy_score(np.array([ind_dict[k] for k in df_test['title']]),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "level-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8547661531502099\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of joint BERT classifier\n",
    "\n",
    "preds = predictions\n",
    "preds = np.argmax(preds, axis=1).flatten()\n",
    "print(sklearn.metrics.accuracy_score(np.array([ind_dict[k] for k in df_test['title']]),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "owned-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539328917838962\n",
      "0.8480624477279063\n"
     ]
    }
   ],
   "source": [
    "# accuracy of decoupled BERT Classifier\n",
    "f = df_test[df_test['gender']==1]\n",
    "reset_f = f.reset_index(drop=True)\n",
    "m = df_test[df_test['gender']==0]\n",
    "reset_m = m.reset_index(drop=True)\n",
    "predictions_f= pkl.load(open('results/decoupled_predictions_bert.pkl','rb'))\n",
    "predictions_f = scipy.special.softmax(predictions_f)\n",
    "predictions_m= pkl.load(open('results/decoupled_predictions_bert_m.pkl','rb'))\n",
    "predictions_m = scipy.special.softmax(predictions_m)\n",
    "print(sklearn.metrics.accuracy_score(np.array([ind_dict[k] for k in f['title']]),np.argmax(predictions_f,axis=1)))\n",
    "print(sklearn.metrics.accuracy_score(np.array([ind_dict[k] for k in m['title']]),np.argmax(predictions_m,axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-electronics",
   "metadata": {},
   "source": [
    "# get rms gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "julian-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes as input a dictionary, outputs accuracy for each subgroup\n",
    "def pred_summary(pred_dic, Y_test, G_test):\n",
    "    #wildcard aggregates over different classes/genders\n",
    "    wildcard = \"*\"\n",
    "    genders = sorted(set(G_test)) + [wildcard]\n",
    "    ys = sorted(set(Y_test)) + [wildcard]\n",
    "    summary =  {y: {g: [] for g in genders} for y in ys} \n",
    "    for y in ys:\n",
    "        for gender in genders:\n",
    "            #print(y,sum(array(Y_test)==y))\n",
    "            #accuracies = []\n",
    "            bool_subgroup = [y_pred==y_true for y_pred, y_true, g in zip(pred_dic, Y_test, G_test) \n",
    "                        if (gender==wildcard or gender==g) and (y==wildcard or y==y_true)]\n",
    "            acc=np.mean(bool_subgroup)\n",
    "            summary[y][gender]=acc    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "previous-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21844847261386127"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rmsgap for decoupled\n",
    "m_summary = pred_summary(np.argmax(predictions_m,axis=1), np.array([ind_dict[k] for k in m['title']]), ['M']*len(m['title']))\n",
    "f_summary = pred_summary(np.argmax(predictions_f,axis=1), np.array([ind_dict[k] for k in f['title']]), ['F']*len(m['title']))\n",
    "\n",
    "dec_gaps =[]\n",
    "for k,v in m_summary.items():\n",
    "    if k is not '*':\n",
    "        print(k)\n",
    "        dec_gaps.append(f_summary[k]['F']-m_summary[k]['M'])\n",
    "dec_gaps =np.array(dec_gaps)\n",
    "np.sqrt(np.sum(np.array(dec_gaps)**2)/28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "statutory-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10836595096949522"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get rmsgap for pre-prpocessing\n",
    "\n",
    "summary = pred_summary(np.argmax(pr_preds,axis=1), np.array([ind_dict[k] for k in df_test['title']]), df_test['gender'])\n",
    "pr_gaps =[]\n",
    "for k,v in summary.items():\n",
    "    if k is not '*':\n",
    "        print(k)\n",
    "        pr_gaps.append(summary[k][0]-summary[k][1])\n",
    "pr_gaps =np.array(pr_gaps)\n",
    "np.sqrt(np.sum(np.array(pr_gaps)**2)/28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-welding",
   "metadata": {},
   "source": [
    "# Cov(r_c, p_c) calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "julian-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1999995 words\n"
     ]
    }
   ],
   "source": [
    "# load word embeddings\n",
    "with open(\"../../words/embeddings/OtherFormats/crawl-300d-2M.pkl\", \"rb\") as f:\n",
    "    E = pkl.load(f)\n",
    "print(\"Loaded\", len(E), \"words\")\n",
    "\n",
    "\n",
    "def sim(w1, w2):\n",
    "    return E[w1].dot(E[w2])/np.linalg.norm(E[w1])/np.linalg.norm(E[w2])\n",
    " \n",
    "sim('he', 'she')\n",
    "\n",
    "\n",
    "def word_vector_featurize_simple(text, Emb = E):\n",
    "    return np.mean([Emb[w] for w in re.split(r\"[\\s\\.\\!\\?\\:,\\\"“\\—\\-\\(\\)]+\", text) if len(w)>1 and w in Emb], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "experienced-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_frac = np.load('results/f_frac.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "active-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024005407377595645"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for decoupled\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "decoupled_occ = []\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "    \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "    gender_probs = balanced_gender_clf.predict_proba(cand_women_X_full)[:,0]\n",
    "    \n",
    "    \n",
    "    Y_test = [ind_dict[p] for p in df_test[\"title\"]]\n",
    "#     print(np.unique(np.array(Y_test)))\n",
    "    y_pred_f = predictions_f[:,occ_ind]\n",
    "    y_pred_m = predictions_m[:,occ_ind]\n",
    "    \n",
    "    \n",
    "    all_preds = np.zeros([len(Y_test)])\n",
    "    all_preds[list(f.index)] = y_pred_f\n",
    "    all_preds[list(m.index)] = y_pred_m\n",
    "    \n",
    "    occ_probs = all_preds[cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "#     print(\"%s %s corr: %.3f, p-value %.3f\" % (target_occ,' '*(20-len(target_occ)),corr, scipy.stats.kendalltau(occ_probs,gender_probs)[1]))\n",
    "    decoupled_occ.append(corr)\n",
    "np.cov(f_frac,decoupled_occ)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fourth-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019997575222467943"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for pr\n",
    "pr_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "        \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "    gender_probs = balanced_gender_clf.predict_proba(cand_women_X_full)[:,0]\n",
    "    \n",
    "    occ_probs = pr_preds[:,occ_ind][cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    pr_occ.append(corr)\n",
    "np.cov(f_frac,pr_occ)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "conventional-associate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02589993808209482\n"
     ]
    }
   ],
   "source": [
    "# for joint (PO)\n",
    "joint_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "        \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "    gender_probs = balanced_gender_clf.predict_proba(cand_women_X_full)[:,0]\n",
    "    \n",
    "    occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    joint_occ.append(corr)\n",
    "print(np.cov(f_frac,joint_occ)[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "greenhouse-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004837378692504763\n"
     ]
    }
   ],
   "source": [
    "# for joint (PO)\n",
    "pr_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "        \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "#     gender_probs = balanced_gender_clf.predict_proba(cand_women_X_full)[:,0]\n",
    "    \n",
    "    occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "    gender_probs = gender_predictions[:,0][cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    pr_occ.append(corr)\n",
    "print(np.cov(f_frac,pr_occ)[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joint (PO)\n",
    "pr_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "        \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "    gender_probs = balanced_gender_clf.predict_proba(cand_women_X_full)[:,0]\n",
    "    \n",
    "    occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    pr_occ.append(corr)\n",
    "np.cov(f_frac,pr_occ)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "pharmaceutical-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297\n",
      "3634\n",
      "3542\n",
      "3835\n",
      "3667\n",
      "3427\n",
      "3779\n",
      "3420\n",
      "2198\n",
      "3364\n",
      "1150\n",
      "2236\n",
      "2201\n",
      "1537\n",
      "2979\n",
      "2619\n",
      "3166\n",
      "3818\n",
      "2865\n",
      "2923\n",
      "3555\n",
      "3923\n",
      "3915\n",
      "3401\n",
      "4003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizers=pkl.load(open('results/bow_chi_vectorizers_or.pkl','rb'))\n",
    "\n",
    "occs = [\"surgeon\", \"software_engineer\", \"composer\", \"pastor\", \"comedian\", \"architect\", \"chiropractor\", \"accountant\", \"attorney\", \"filmmaker\", \"physician\", \"dentist\", \"photographer\", \"professor\", \"painter\", \"journalist\", \"poet\", \"personal_trainer\", \"teacher\", \"psychologist\",  \"model\", \"interior_designer\", \"yoga_teacher\", \"nurse\", \"dietitian\"]\n",
    "\n",
    "from scipy.stats import chi2\n",
    "prob = 0.99\n",
    "critical = chi2.ppf(prob, 1)\n",
    "occupation_embeddings = {}\n",
    "\n",
    "thr = critical\n",
    "for occ in occs:\n",
    "    \n",
    "    all_words = list(vectorizers[occ][thr].vocabulary_.keys())\n",
    "    print(len(all_words))\n",
    "    new_dict = {}\n",
    "    for w in all_words:\n",
    "        if w in E:\n",
    "            new_dict[w] = E[w]\n",
    "    occupation_embeddings[occ+\"%.2f\"%thr] = new_dict\n",
    "\n",
    "    \n",
    "def word_vector_featurize(text, occupation, Emb = E):\n",
    "    return mean([occupation_embeddings[occupation + \"%.2f\"%critical][w] for w in re.split(r\"[\\s\\.\\!\\?\\:,\\\"“\\—\\-\\(\\)]+\", text) if len(w)>1 and w in occupation_embeddings[occupation+ \"%.2f\"%critical]], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-iraqi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "olive-training",
   "metadata": {},
   "source": [
    "# get corrs w g_irrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "golden-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get word embedding of each bio, including only task-irrelevant words\n",
    "def process_bios(bio_dict,occ):\n",
    "    irrev_corr_X_train = [word_vector_featurize(p[\"bio\"].lower(), occ, E) for i,p in bio_dict.iterrows()]\n",
    "    train_inds = []\n",
    "    for i,p in enumerate(irrev_corr_X_train):\n",
    "        if isinstance(p, np.ndarray):\n",
    "            train_inds.append(i)\n",
    "    irrev_corr_X_train_new = [irrev_corr_X_train[i] for i in range(len(bio_dict)) if i in train_inds]\n",
    "    return irrev_corr_X_train_new, train_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "covered-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_gender_classers = pkl.load(open('results/we_chi_gender_classers_or.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "formed-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_gender_classers[target_occ][thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "impressive-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/adam/Dropbox/WorkProjects/venv_main/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002711358125551234\n",
      "0.006919011441870298\n",
      "0.0031530784825718806\n"
     ]
    }
   ],
   "source": [
    "pre_corr = []\n",
    "joint_corr = []\n",
    "decoupled_corr =[]\n",
    "for i_index, target_occ in enumerate(occs):\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "    \n",
    "#     cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "    cand_women_X,inds = process_bios(cand_women, target_occ) #removes bios that are null when take out words\n",
    "#     cand_women_X_full = np.array(cand_women_X_full)[inds] #remove them from the full one\n",
    "    cand_inds = cand_inds[inds]\n",
    "    gender_probs = chi_gender_classers[target_occ][thr].predict_proba(cand_women_X)[:,0]\n",
    "    occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    joint_corr.append(corr)\n",
    "\n",
    "    occ_probs = pr_preds[:,occ_ind][cand_inds]\n",
    "\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    pre_corr.append(corr)\n",
    "\n",
    "    decoupled_inds = np.array(reset_f.loc[reset_f['title']==target_occ].index)[inds]\n",
    "    occ_probs = predictions_f[:,occ_ind][decoupled_inds]\n",
    "\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    decoupled_corr.append(corr)\n",
    "    \n",
    "print(np.cov(f_frac,pre_corr)[0,1])\n",
    "print(np.cov(f_frac,joint_corr)[0,1])\n",
    "print(np.cov(f_frac,decoupled_corr)[0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "assumed-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008809819459988751\n",
      "0.006799586250270358\n",
      "0.0034634243742574216\n"
     ]
    }
   ],
   "source": [
    "print(np.cov(f_frac,pre_corr)[0,1])\n",
    "print(np.cov(f_frac,joint_corr)[0,1])\n",
    "print(np.cov(f_frac,decoupled_corr)[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "shared-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02364793828046382\n",
      "0.18500395898918956\n",
      "0.0893235850465698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pearsonr(f_frac,pre_corr)[0])\n",
    "print(pearsonr(f_frac,joint_corr)[0])\n",
    "print(pearsonr(f_frac,decoupled_corr)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "loose-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x=='F' for x in gender_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "animal-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4812454547306294\n",
      "0.42963991680833624\n",
      "0.4009021411263073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(pearsonr(f_frac,joint_occ[:25])[0])\n",
    "print(pearsonr(f_frac,decoupled_occ[:25])[0])\n",
    "print(pearsonr(f_frac,pr_occ[:25])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "coordinate-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4812454547306294\n",
      "0.4815384615384616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pearsonr(f_frac,joint_occ[:25])[0])\n",
    "print(spearmanr(f_frac,decoupled_occ[:25])[0])\n",
    "# print(spearmanr(f_frac,pr_occ[:25])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "executive-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06692307692307692\n",
      "-0.03538461538461538\n",
      "-0.04538461538461538\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print(spearmanr(f_frac,joint_corr[:25])[0])\n",
    "print(spearmanr(f_frac,decoupled_corr[:25])[0])\n",
    "print(spearmanr(f_frac,pre_corr[:25])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "agreed-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1747719529413357\n",
      "0.07383587167004851\n",
      "0.06448287087871646\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(f_frac,joint_corr[:25])[0])\n",
    "print(pearsonr(f_frac,decoupled_corr[:25])[0])\n",
    "print(pearsonr(f_frac,pre_corr[:25])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "reasonable-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_inds  = np.where(abs(f_frac-0.5)>0.25)[0]\n",
    "def imb_pearsonr(l):\n",
    "#     print(\"Pearson's r\")\n",
    "    print(scipy.stats.pearsonr(f_frac[imbalanced_inds],np.array(l)[imbalanced_inds])[0])\n",
    "    \n",
    "def imb_cov(l):\n",
    "#     print(\"Covariance\")\n",
    "    print(np.cov(f_frac[imbalanced_inds],np.array(l)[imbalanced_inds])[0,1]) \n",
    "    \n",
    "def imb_spear(l):\n",
    "#     print(\"Spearman's r\")\n",
    "    print(scipy.stats.spearmanr(f_frac[imbalanced_inds],np.array(l)[imbalanced_inds])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "correct-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2830772656490382\n",
      "0.16700496180950533\n",
      "0.164843601635229\n",
      "0.03636363636363637\n",
      "-0.1272727272727273\n",
      "-0.02727272727272728\n",
      "0.018831260858120563\n",
      "0.011256762232153213\n",
      "0.010080136682544873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imb_pearsonr(joint_corr)\n",
    "imb_pearsonr(decoupled_corr)\n",
    "imb_pearsonr(pre_corr)\n",
    "\n",
    "imb_spear(joint_corr)\n",
    "imb_spear(decoupled_corr)\n",
    "imb_spear(pre_corr)\n",
    "\n",
    "imb_cov(joint_corr)\n",
    "imb_cov(decoupled_corr)\n",
    "imb_cov(pre_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "transsexual-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6268657470315026\n",
      "0.5886323224904346\n",
      "0.5621829616007565\n",
      "0.5090909090909091\n",
      "0.4727272727272727\n",
      "0.3272727272727273\n",
      "0.06307462380370318\n",
      "0.05955358220757176\n",
      "0.04690800887102422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imb_pearsonr(joint_occ)\n",
    "imb_pearsonr(decoupled_occ)\n",
    "imb_pearsonr(pr_occ)\n",
    "\n",
    "imb_spear(joint_occ)\n",
    "imb_spear(decoupled_occ)\n",
    "imb_spear(pr_occ)\n",
    "\n",
    "imb_cov(joint_occ)\n",
    "imb_cov(decoupled_occ)\n",
    "imb_cov(pr_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "olympic-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.46307692307692305, pvalue=0.01974462362857622)\n",
      "SpearmanrResult(correlation=0.4815384615384616, pvalue=0.014800630192683392)\n",
      "SpearmanrResult(correlation=0.43999999999999995, pvalue=0.02773337204061013)\n"
     ]
    }
   ],
   "source": [
    "# rev\n",
    "print(spearmanr(f_frac,joint_occ[:25]))\n",
    "print(spearmanr(f_frac,decoupled_occ[:25]))\n",
    "print(spearmanr(f_frac,pr_occ[:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "nearby-plant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.06692307692307692, pvalue=0.7506056746243597)\n",
      "SpearmanrResult(correlation=-0.03538461538461538, pvalue=0.8666482296036683)\n",
      "SpearmanrResult(correlation=-0.04538461538461538, pvalue=0.8294429316309466)\n"
     ]
    }
   ],
   "source": [
    "#irrev\n",
    "print(spearmanr(f_frac,joint_corr[:25]))\n",
    "print(spearmanr(f_frac,decoupled_corr[:25]))\n",
    "print(spearmanr(f_frac,pre_corr[:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "quality-degree",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-3e8002dfac90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#     print(\"%s %s corr: %.3f, p-value %.3f\" % (target_occ,' '*(20-len(target_occ)),corr, scipy.stats.kendalltau(occ_probs,gender_probs)[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdecoupled_occ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_frac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoupled_occ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# for decoupled\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "decoupled_occ = []\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "    \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "    gender_probs = gender_predictions[:,0][cand_inds]\n",
    "    \n",
    "    \n",
    "    Y_test = [ind_dict[p] for p in df_test[\"title\"]]\n",
    "#     print(np.unique(np.array(Y_test)))\n",
    "    y_pred_f = predictions_f[:,occ_ind]\n",
    "    y_pred_m = predictions_m[:,occ_ind]\n",
    "    \n",
    "    \n",
    "    all_preds = np.zeros([len(Y_test)])\n",
    "    all_preds[list(f.index)] = y_pred_f\n",
    "    all_preds[list(m.index)] = y_pred_m\n",
    "    \n",
    "    occ_probs = all_preds[cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "#     print(\"%s %s corr: %.3f, p-value %.3f\" % (target_occ,' '*(20-len(target_occ)),corr, scipy.stats.kendalltau(occ_probs,gender_probs)[1]))\n",
    "    decoupled_occ.append(corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "finished-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.09, pvalue=0.6687736167185602)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(f_frac,decoupled_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "certified-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.10461538461538461, pvalue=0.6187190398978742)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for joint (PO)\n",
    "pr_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in occs:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "        \n",
    "    cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "    gender_probs = gender_predictions[:,0][cand_inds]\n",
    "    \n",
    "    occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "    corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "    pr_occ.append(corr)\n",
    "spearmanr(f_frac,pr_occ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "least-petersburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10677\n"
     ]
    }
   ],
   "source": [
    "# for joint (PO)\n",
    "pr_occ=[]\n",
    "\n",
    "G_test = np.array(df_test[\"gender\"])\n",
    "\n",
    "for target_occ in ['professor']:\n",
    "    occ_ind = ind_dict[target_occ]\n",
    "    \n",
    "    cand_women = df_test[df_test[\"title\"]==target_occ]\n",
    "    \n",
    "    \n",
    "    cand_women = cand_women[cand_women['gender']==1]\n",
    "    \n",
    "    cand_inds = np.array(df_test.loc[(df_test['gender']==1) & (df_test['title']==target_occ)].index)\n",
    "    print(len(cand_inds))\n",
    "#     cand_women_X_full =  [word_vector_featurize_simple(p[\"bio\"], E) for i,p in cand_women.iterrows()]\n",
    "\n",
    "#     gender_probs = gender_predictions[:,0][cand_inds]\n",
    "    \n",
    "#     occ_probs = predictions[:,occ_ind][cand_inds]\n",
    "#     corr = scipy.stats.spearmanr(occ_probs,gender_probs)[0]\n",
    "#     pr_occ.append(corr)\n",
    "# spearmanr(f_frac,pr_occ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-bracelet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
